{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce13ea15",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch\n",
    "Lecturers = R. Patrick Xian, Santosh Adhikari, Sourin Dey<br>\n",
    "Date = 07/2022\n",
    "\n",
    "[Pytorch cheatsheet](https://pytorch.org/tutorials/beginner/ptcheat.html)\n",
    "\n",
    "### Use of Pytorch nowadays (2022):\n",
    "- ### Research-grade deep learning model building\n",
    "- ### High-performance computational tools that benefits from [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) / autodifferentiation, such as those that directly include or can be translated into optimization problems\n",
    "- ### Probabilistic inference engine\n",
    "- ### Prototyping machine-learning apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbcf9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743043e",
   "metadata": {},
   "source": [
    "## 1. Data types\n",
    "### 1.1 ```torch.tensor``` / ```torch.Tensor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77dd706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.tensor([[1, 2], [3, 4]])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05913f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aa73f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape is a property for tensor object\n",
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e2c9fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numel (number of elements) is a method for tensor object, which is equivalent to the size of numpy array\n",
    "ts.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13d27772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent to above\n",
    "torch.numel(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f7882b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df556e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create torch tensor from \n",
    "# Compa\n",
    "torch.linspace(0, 4, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92d589c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 4, 9, endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb993fe5",
   "metadata": {},
   "source": [
    "### 1.2 Interoperability with ```numpy```\n",
    "Conversion from ```numpy.ndarray``` to ```torch.tensor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31f79c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
       "       [ 1.86755799, -0.97727788,  0.95008842, -0.15135721],\n",
       "       [-0.10321885,  0.4105985 ,  0.14404357,  1.45427351]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "arr = np.random.randn(3, 4)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf9e26f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7641,  0.4002,  0.9787,  2.2409],\n",
       "        [ 1.8676, -0.9773,  0.9501, -0.1514],\n",
       "        [-0.1032,  0.4106,  0.1440,  1.4543]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tarr = torch.from_numpy(arr)\n",
    "tarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863af469",
   "metadata": {},
   "source": [
    "Conversion from ```torch.tensor``` to ```numpy.ndarray```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75e2a6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_arr = ts.numpy()\n",
    "ts_arr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ebcbb82",
   "metadata": {},
   "source": [
    "## 2. Building deep learning models\n",
    "### 2.1 Neural network basics\n",
    "\n",
    "A neural network is an overparametrized functional approximator. It is modeled loosely after neural networks in animal and human brains.\n",
    "\n",
    "#### [Universal approximation theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem) (Hornik 1991): A neural network with a hidden layer of infinite width can approximate any function.\n",
    "\n",
    "Single layer neural network: $f_1 = g(w^Tx + b)$\n",
    "<br>\n",
    "N-layer neural network: $f_N = g(w_N^T(w_{N-1}^T(...(w_1^Tx + b_1) + b_{N-1}) + b_N)$\n",
    "<img src=\"NN.png\" alt=\"isolated\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6ef336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934790a5",
   "metadata": {},
   "source": [
    "### 2.2 A neural network that simulates the XOR operation\n",
    "\n",
    "- Why XOR? (XOR = exclusive or)<br>\n",
    "XOR is the simplest nonlinear function with a vector input and scalar output.\n",
    "\n",
    "| A | B | A XOR B |\n",
    "|---|---|---------|\n",
    "| 0 | 0 | 0       |\n",
    "| 0 | 1 | 1       |\n",
    "| 1 | 0 | 1       |\n",
    "| 1 | 1 | 0       |\n",
    "\n",
    "<br>\n",
    "We need to use the neural network to represent $f$, such that $f \\sim$ XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4bee3e",
   "metadata": {},
   "source": [
    "#### Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e6c7c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.tensor([[0., 0.],\n",
    "                   [0., 1.],\n",
    "                   [1., 0.],\n",
    "                   [1., 1.]])\n",
    "\n",
    "y = torch.tensor([0., 1., 1., 0.]).reshape(Xs.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89752bea",
   "metadata": {},
   "source": [
    "#### Build neural network (XORNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df769cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XORNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(XORNet, self).__init__()\n",
    "        \n",
    "        # Set the first linear layer\n",
    "        self.linear1 = nn.Linear(2, 2)\n",
    "        \n",
    "        # Set the activation function\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Set the output layer\n",
    "        self.linear2 = nn.Linear(2, 1)\n",
    "    \n",
    "    # Define forward pass through the neural network\n",
    "    def forward(self, input):\n",
    "        \n",
    "        x = self.linear1(input)\n",
    "        sig = self.Sigmoid(x)\n",
    "        yh = self.linear2(sig)\n",
    "        \n",
    "        return yh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd7d26",
   "metadata": {},
   "source": [
    "#### Initiate and summarize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cc5886ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Linear: 1-1                            6\n",
      "├─Sigmoid: 1-2                           --\n",
      "├─Linear: 1-3                            3\n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initiate neural network\n",
    "xor_network = XORNet()\n",
    "\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    summary(xor_network);\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef703dfc",
   "metadata": {},
   "source": [
    "#### Set network training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "98424fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training epochs\n",
    "epochs = 1000\n",
    "\n",
    "# Define training loss function\n",
    "mseloss = nn.MSELoss()\n",
    "\n",
    "# Select optimizer\n",
    "optimizer = torch.optim.Adam(xor_network.parameters(), lr = 0.03)\n",
    "\n",
    "all_losses = [] \n",
    "current_loss = 0\n",
    "sample_every = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b011f",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5304593a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 completed\n",
      "Epoch: 100 completed\n",
      "Epoch: 200 completed\n",
      "Epoch: 300 completed\n",
      "Epoch: 400 completed\n",
      "Epoch: 500 completed\n",
      "Epoch: 600 completed\n",
      "Epoch: 700 completed\n",
      "Epoch: 800 completed\n",
      "Epoch: 900 completed\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs): \n",
    "   \n",
    "    # input training example and return the prediction   \n",
    "    yhat = xor_network.forward(Xs)\n",
    "    \n",
    "    # calculate MSE loss   \n",
    "    loss = mseloss(yhat, y)\n",
    "      \n",
    "    # backpropogate through the loss gradiants   \n",
    "    loss.backward()\n",
    "    \n",
    "    # update model weights   \n",
    "    optimizer.step()\n",
    "    \n",
    "    # remove current gradients for next iteration   \n",
    "    optimizer.zero_grad() \n",
    "   \n",
    "    # append to loss   \n",
    "    current_loss += loss  \n",
    " \n",
    "    if epoch % sample_every == 0:       \n",
    "        all_losses.append(current_loss / plot_every)       \n",
    "        current_loss = 0 \n",
    "     \n",
    "    # print progress\n",
    "    if epoch % (sample_every*2) == 0:\n",
    "        print(f'Epoch: {epoch} completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735371ef",
   "metadata": {},
   "source": [
    "#### Plot loss function during the training of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7daf6053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Training epoch')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_sampled = int(epochs / sample_every)\n",
    "sampled_epochs = [i*sample_every for i in range(n_sampled)]\n",
    "plt.plot(sampled_epochs[1:], all_losses[1:])\n",
    "plt.ylabel('Loss', fontsize=20);\n",
    "plt.xticks(range(0, epochs, 100))\n",
    "plt.xlim([0, epochs])\n",
    "plt.xlabel('Training epoch', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5402ff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight tensor([[-2.6372, -2.6383],\n",
      "        [-3.5483, -3.5519]])\n",
      "linear1.bias tensor([3.4040, 0.8121])\n",
      "linear2.weight tensor([[ 2.0913, -2.5266]])\n",
      "linear2.bias tensor([-0.2742])\n"
     ]
    }
   ],
   "source": [
    "for name, param in xor_network.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a78454",
   "metadata": {},
   "source": [
    "#### Test out the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "56089ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input = [0. 0.], output = [0.]\n",
      "Input = [0. 1.], output = [1.]\n",
      "Input = [1. 0.], output = [1.]\n",
      "Input = [1. 1.], output = [0.]\n"
     ]
    }
   ],
   "source": [
    "for input_vector in Xs:\n",
    "\n",
    "    # Calculate prediction outcome\n",
    "    out = xor_network(input_vector)\n",
    "    invec = input_vector.detach().numpy()\n",
    "    outval = out.round().detach().numpy()\n",
    "    print('Input = {}, output = {}'.format(invec, outval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ffdad",
   "metadata": {},
   "source": [
    "## 3. Model storage and reuse\n",
    "### 3.1 What constitutes a model and what needs to be stored?\n",
    "\n",
    "- Weight matrices (w), biases (b), network architecture (hyper)parameters\n",
    "- Optimization parameters\n",
    "- Sampling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "98d68e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[-2.6372, -2.6383],\n",
       "                      [-3.5483, -3.5519]])),\n",
       "             ('linear1.bias', tensor([3.4040, 0.8121])),\n",
       "             ('linear2.weight', tensor([[ 2.0913, -2.5266]])),\n",
       "             ('linear2.bias', tensor([-0.2742]))])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_network.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b337ab",
   "metadata": {},
   "source": [
    "### 3.2 Storing and loading model using Pytorch format\n",
    "Pytorch file extension ```.pt``` or ```.pth```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dd2faece",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(xor_network.state_dict(), r'.\\xor_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7321105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86686581",
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_nn_dict = torch.load(r'.\\xor_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "99506e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_nn = XORNet().load_state_dict(xor_nn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5313c60",
   "metadata": {},
   "source": [
    "### 3.3 Storing model using [ONNX](https://onnx.ai/) (Open Neural Network Exchange) format\n",
    "We use the [Pytorch specification of ONNX](https://pytorch.org/docs/master/onnx.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "25bb5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as tonnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aa167be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tonnx.export(xor_network, Xs, r'.\\xor_nn.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d0a70d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
