{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d502a8d",
   "metadata": {},
   "source": [
    "# Introduction to Pytorch\n",
    "Lecturers = R. Patrick Xian, Santosh Adhikari, Sourin Dey<br>\n",
    "Date = 07/2022\n",
    "\n",
    "[Pytorch cheatsheet](https://pytorch.org/tutorials/beginner/ptcheat.html)\n",
    "\n",
    "### Use of Pytorch nowadays (2022):\n",
    "- ### Building research-grade deep learning models\n",
    "- ### High-performance computational tools that benefits from [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) / autodifferentiation, such as those that directly include or can be translated into optimization problems\n",
    "- ### Probabilistic inference engine\n",
    "- ### Prototyping machine-learning apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1b695d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "05c871e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let computation be carried out on the CPU\n",
    "torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cab521",
   "metadata": {},
   "source": [
    "## 1. Data types\n",
    "### 1.1 ```torch.tensor``` / ```torch.Tensor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80bf96d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.tensor([[1, 2], [3, 4]])\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631fef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.is_tensor(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce6d536b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape is a property for tensor object\n",
    "ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d168e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numel (number of elements) is a method for tensor object, which is equivalent to the size of numpy array\n",
    "ts.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e6e301f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Equivalent to above\n",
    "torch.numel(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a06583f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84cff015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create torch tensor from \n",
    "# Compa\n",
    "torch.linspace(0, 4, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1c084b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 4, 9, endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d2a55c",
   "metadata": {},
   "source": [
    "### 1.2 Interoperability with ```numpy```\n",
    "Conversion from ```numpy.ndarray``` to ```torch.tensor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9867ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
       "       [ 1.86755799, -0.97727788,  0.95008842, -0.15135721],\n",
       "       [-0.10321885,  0.4105985 ,  0.14404357,  1.45427351]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "arr = np.random.randn(3, 4)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6d3390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7641,  0.4002,  0.9787,  2.2409],\n",
       "        [ 1.8676, -0.9773,  0.9501, -0.1514],\n",
       "        [-0.1032,  0.4106,  0.1440,  1.4543]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tarr = torch.from_numpy(arr)\n",
    "tarr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5feb8",
   "metadata": {},
   "source": [
    "Conversion from ```torch.tensor``` to ```numpy.ndarray```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c25208dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_arr = ts.numpy()\n",
    "ts_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600b8b7",
   "metadata": {},
   "source": [
    "### 1.3 Interoperability with ```pandas```\n",
    "Conversion from ```pandas.DataFrame``` to ```torch.tensor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b76db02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "785d67e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>2.240893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.867558</td>\n",
       "      <td>-0.977278</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>-0.151357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>0.144044</td>\n",
       "      <td>1.454274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.764052  0.400157  0.978738  2.240893\n",
       "1  1.867558 -0.977278  0.950088 -0.151357\n",
       "2 -0.103219  0.410599  0.144044  1.454274"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(arr)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "31479ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7641,  0.4002,  0.9787,  2.2409],\n",
       "        [ 1.8676, -0.9773,  0.9501, -0.1514],\n",
       "        [-0.1032,  0.4106,  0.1440,  1.4543]], dtype=torch.float64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5076f61e",
   "metadata": {},
   "source": [
    "Conversion from ```torch.tensor``` to ```pandas.DataFrame```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9358630e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.764052</td>\n",
       "      <td>0.400157</td>\n",
       "      <td>0.978738</td>\n",
       "      <td>2.240893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.867558</td>\n",
       "      <td>-0.977278</td>\n",
       "      <td>0.950088</td>\n",
       "      <td>-0.151357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.103219</td>\n",
       "      <td>0.410599</td>\n",
       "      <td>0.144044</td>\n",
       "      <td>1.454274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.764052  0.400157  0.978738  2.240893\n",
       "1  1.867558 -0.977278  0.950088 -0.151357\n",
       "2 -0.103219  0.410599  0.144044  1.454274"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tarr.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72b5caa4",
   "metadata": {},
   "source": [
    "## 2. Building deep learning models\n",
    "### 2.0 Essentials for machine learning models\n",
    "A machine learning-ready question requires the following ingredients\n",
    "1. A question to solve along with mathematical formulation\n",
    "2. At least one relevant dataset paired with features ($X$, $y$)\n",
    "3. Predictive model $M$ (including algorithm and architecture)\n",
    "4. Optimization method / optimizer\n",
    "5. Error metric / Loss function / Objective function $L$\n",
    "6. Model training method or scheduler\n",
    "7. Hyperparameter tuner\n",
    "\n",
    "Nice to have\n",
    "1. Prediction benchmarks\n",
    "2. Alternative / New datasets\n",
    "3. Deployment platform\n",
    "\n",
    "### 2.1 Neural network basics\n",
    "\n",
    "A neural network is an overparametrized functional approximator. It is modeled loosely after neural networks in animal and human brains.\n",
    "\n",
    "#### [Universal approximation theorem](https://en.wikipedia.org/wiki/Universal_approximation_theorem) (Hornik 1991): A neural network with a hidden layer of infinite width can approximate any function.\n",
    "\n",
    "Single layer neural network: $f_1 = g(w^TX + b)$\n",
    "<br>\n",
    "N-layer neural network: $f_N = g(w_N^T(w_{N-1}^T(...(w_1^Tx + b_1) + b_{N-1}) + b_N)$\n",
    "<img src=\"NN.png\" alt=\"isolated\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e6925d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66251f1f",
   "metadata": {},
   "source": [
    "### 2.2 A neural network that simulates the XOR operator (a [Boolean function](https://en.wikipedia.org/wiki/Boolean_function))\n",
    "\n",
    "- Why XOR? (XOR = exclusive or)<br>\n",
    "XOR is the simplest nonlinear function with a vector input and scalar output, with the following truth table\n",
    "\n",
    "| A | B | A XOR B |\n",
    "|---|---|---------|\n",
    "| 0 | 0 | 0       |\n",
    "| 0 | 1 | 1       |\n",
    "| 1 | 0 | 1       |\n",
    "| 1 | 1 | 0       |\n",
    "\n",
    "<br>\n",
    "We need to use the neural network as a function approximator $f_{\\mathrm{NN}}$ to represent the Boolean function XOR, such that $f_{\\mathrm{NN}} \\sim$ XOR\n",
    "\n",
    "\n",
    "Loss function: mean squared error $\\sum_i(y_i - \\hat{y_i})^2 / N$ for $N$ data points\n",
    "\n",
    "Optimizer: [Adam](https://arxiv.org/abs/1412.6980), a first-order stochastic gradient descent-based optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5918be1",
   "metadata": {},
   "source": [
    "#### (1) Collect or generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0af390e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.tensor([[0., 0.],\n",
    "                   [0., 1.],\n",
    "                   [1., 0.],\n",
    "                   [1., 1.]])\n",
    "\n",
    "y = torch.tensor([0., 1., 1., 0.]).reshape(Xs.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df72c9",
   "metadata": {},
   "source": [
    "#### (2) Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ea2fc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a neural network called XORNet\n",
    "\n",
    "class XORNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(XORNet, self).__init__()\n",
    "        \n",
    "        # Set the first linear layer\n",
    "        self.linear1 = nn.Linear(2, 2)\n",
    "        \n",
    "        # Set the activation function\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # Set the output layer\n",
    "        self.linear2 = nn.Linear(2, 1)\n",
    "    \n",
    "    # Define forward pass through the neural network\n",
    "    def forward(self, input):\n",
    "        \n",
    "        x = self.linear1(input)\n",
    "        sig = self.Sigmoid(x)\n",
    "        yh = self.linear2(sig)\n",
    "        \n",
    "        return yh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2d780",
   "metadata": {},
   "source": [
    "#### (3) Initiate and summarize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "288ab929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Linear: 1-1                            6\n",
      "├─Sigmoid: 1-2                           --\n",
      "├─Linear: 1-3                            3\n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Initiate neural network\n",
    "xor_network = XORNet()\n",
    "\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    summary(xor_network, verbose=1)\n",
    "except:\n",
    "    !pip install torch-summary\n",
    "    print('Please run this cell again after installation!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0193f",
   "metadata": {},
   "source": [
    "#### (4) Determine network training settings\n",
    "Including but are not limited to\n",
    "- loss function\n",
    "- optimizer and hyperparameters (learning rate, weight decay, etc.)\n",
    "- number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "fc16044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set total training epochs\n",
    "epochs = 800\n",
    "\n",
    "# Define training loss function\n",
    "mseloss = nn.MSELoss()\n",
    "\n",
    "# Select and initialize the optimizer\n",
    "optimizer = optim.Adam(xor_network.parameters(), lr = 0.03)\n",
    "\n",
    "all_losses = [] \n",
    "current_loss = 0\n",
    "sample_every = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78651bb6",
   "metadata": {},
   "source": [
    "#### (5) Model training (and hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "60e8a703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 completed\n",
      "Epoch: 100 completed\n",
      "Epoch: 200 completed\n",
      "Epoch: 300 completed\n",
      "Epoch: 400 completed\n",
      "Epoch: 500 completed\n",
      "Epoch: 600 completed\n",
      "Epoch: 700 completed\n"
     ]
    }
   ],
   "source": [
    "# Loop over each training epoch\n",
    "for epoch in range(epochs): \n",
    "   \n",
    "    # input training example and return the prediction   \n",
    "    yhat = xor_network.forward(Xs)\n",
    "    \n",
    "    # calculate MSE loss   \n",
    "    loss = mseloss(yhat, y)\n",
    "      \n",
    "    # backpropogate through the loss gradiants   \n",
    "    loss.backward()\n",
    "    \n",
    "    # update model weights   \n",
    "    optimizer.step()\n",
    "    \n",
    "    # remove current gradients for next iteration   \n",
    "    optimizer.zero_grad() \n",
    "   \n",
    "    # append to loss   \n",
    "    current_loss += loss  \n",
    " \n",
    "    if epoch % sample_every == 0:       \n",
    "        all_losses.append(current_loss / sample_every)       \n",
    "        current_loss = 0\n",
    "     \n",
    "    # print progress every sample_every*2 epochs\n",
    "    if epoch % (sample_every*2) == 0:\n",
    "        print('Epoch: {} completed'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "61f19f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XORNet(\n",
       "  (linear1): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (linear2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85b566",
   "metadata": {},
   "source": [
    "#### (6) Visualize loss function during the training of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a29c8344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Training epoch')"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_sampled = int(epochs / sample_every)\n",
    "sampled_epochs = [i*sample_every for i in range(n_sampled)]\n",
    "\n",
    "plt.plot(sampled_epochs[1:], all_losses[1:])\n",
    "plt.ylabel('Loss', fontsize=20);\n",
    "plt.xticks(range(0, epochs, 100))\n",
    "plt.xlim([0, epochs])\n",
    "plt.xlabel('Training epoch', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "06c5ac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight tensor([[-4.6231, -4.4772],\n",
      "        [-2.9024, -2.8796]])\n",
      "linear1.bias tensor([1.0845, 3.6311])\n",
      "linear2.weight tensor([[-2.1656,  1.8595]])\n",
      "linear2.bias tensor([-0.1931])\n"
     ]
    }
   ],
   "source": [
    "# Print out the neural network parameters\n",
    "for name, param in xor_network.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b14e6",
   "metadata": {},
   "source": [
    "#### (7) Test out the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "e927896d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input_vector in Xs:\n",
    "\n",
    "#     # Calculate prediction outcome\n",
    "#     out = xor_network(input_vector)\n",
    "#     invec = input_vector.detach().numpy()\n",
    "#     outval = out.round().detach().numpy()\n",
    "#     print('Input = {}, output = {}'.format(invec, outval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "40738d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(data, model, verbose=False):\n",
    "    \"\"\" Evaluate model given data.\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    for datum in data:\n",
    "        result = model(datum)\n",
    "        results.append(result)\n",
    "        \n",
    "        # If the verbose option is specified, print out the intermediate outcomes.\n",
    "        if verbose:\n",
    "            datum_vec = datum.detach().numpy()\n",
    "            res_vec = result.round().detach().numpy()\n",
    "            print('Input = {}, output = {}'.format(datum_vec, res_vec))\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "77d4d077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input = [0. 0.], output = [-0.]\n",
      "Input = [0. 1.], output = [1.]\n",
      "Input = [1. 0.], output = [1.]\n",
      "Input = [1. 1.], output = [0.]\n"
     ]
    }
   ],
   "source": [
    "eval_model(Xs, xor_network, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec092c8c",
   "metadata": {},
   "source": [
    "## 3. Model storage and reuse\n",
    "### 3.1 What constitutes a model and what needs to be stored?\n",
    "\n",
    "- Weight matrices (w), biases (b), network architecture (hyper)parameters (**must-haves**)\n",
    "- Optimization (hyper)parameters\n",
    "- Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8148a077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[-5.2579,  5.4862],\n",
       "                      [ 2.7224, -2.7568]])),\n",
       "             ('linear1.bias', tensor([-3.6438, -1.2806])),\n",
       "             ('linear2.weight', tensor([[1.6142, 1.7604]])),\n",
       "             ('linear2.bias', tensor([-0.4239]))])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_network.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d8380",
   "metadata": {},
   "source": [
    "### 3.2 Storing and loading model using the Pytorch format\n",
    "Save Pytorch model to file with extension ```.pt``` or ```.pth```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "11f24f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'xor_net':xor_network.state_dict()}, r'.\\xor_nn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "120e3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check that the model is exported\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1e84d",
   "metadata": {},
   "source": [
    "Load the trained Pytorch neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "08418e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[-2.6372, -2.6383],\n",
       "                      [-3.5483, -3.5519]])),\n",
       "             ('linear1.bias', tensor([3.4040, 0.8121])),\n",
       "             ('linear2.weight', tensor([[ 2.0913, -2.5266]])),\n",
       "             ('linear2.bias', tensor([-0.2742]))])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_nn_dict = torch.load(r'.\\xor_nn.pt')['xor_net']\n",
    "xor_nn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "177e2a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XORNet(\n",
       "  (linear1): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (Sigmoid): Sigmoid()\n",
       "  (linear2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_nn = XORNet()\n",
    "xor_nn.load_state_dict(xor_nn_dict)\n",
    "xor_nn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6642ef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input = [0. 0.], output = [0.]\n",
      "Input = [0. 1.], output = [1.]\n",
      "Input = [1. 0.], output = [1.]\n",
      "Input = [1. 1.], output = [0.]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate loaded network\n",
    "eval_model(Xs, xor_nn, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca02122",
   "metadata": {},
   "source": [
    "### 3.3 Storing model using the [ONNX](https://onnx.ai/) (Open Neural Network Exchange) format\n",
    "We use the [Pytorch specification of ONNX](https://pytorch.org/docs/master/onnx.html). The rationale in converting to ```.onnx``` is its faster deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c885de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as tonnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "12b938a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tonnx.export(xor_network, Xs, r'.\\xor_nn.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "eb563bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check that the model is exported\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "29972c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# If not installed, please do command line installation\n",
    "# conda install -c conda-forge onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5c511ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load(r'.\\xor_nn.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "9c539a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 6\n",
      "producer_name: \"pytorch\"\n",
      "producer_version: \"1.9\"\n",
      "graph {\n",
      "  node {\n",
      "    input: \"input.1\"\n",
      "    input: \"linear1.weight\"\n",
      "    input: \"linear1.bias\"\n",
      "    output: \"5\"\n",
      "    name: \"Gemm_0\"\n",
      "    op_type: \"Gemm\"\n",
      "    attribute {\n",
      "      name: \"alpha\"\n",
      "      f: 1.0\n",
      "      type: FLOAT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"beta\"\n",
      "      f: 1.0\n",
      "      type: FLOAT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"transB\"\n",
      "      i: 1\n",
      "      type: INT\n",
      "    }\n",
      "  }\n",
      "  node {\n",
      "    input: \"5\"\n",
      "    output: \"6\"\n",
      "    name: \"Sigmoid_1\"\n",
      "    op_type: \"Sigmoid\"\n",
      "  }\n",
      "  node {\n",
      "    input: \"6\"\n",
      "    input: \"linear2.weight\"\n",
      "    input: \"linear2.bias\"\n",
      "    output: \"7\"\n",
      "    name: \"Gemm_2\"\n",
      "    op_type: \"Gemm\"\n",
      "    attribute {\n",
      "      name: \"alpha\"\n",
      "      f: 1.0\n",
      "      type: FLOAT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"beta\"\n",
      "      f: 1.0\n",
      "      type: FLOAT\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"transB\"\n",
      "      i: 1\n",
      "      type: INT\n",
      "    }\n",
      "  }\n",
      "  name: \"torch-jit-export\"\n",
      "  initializer {\n",
      "    dims: 2\n",
      "    dims: 2\n",
      "    data_type: FLOAT\n",
      "    name: \"linear1.weight\"\n",
      "    raw_data: \"B\\307(\\300i\\332(\\300\\347\\026c\\300\\014Sc\\300\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 2\n",
      "    data_type: FLOAT\n",
      "    name: \"linear1.bias\"\n",
      "    raw_data: \"\\246\\333Y@@\\347O?\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 1\n",
      "    dims: 2\n",
      "    data_type: FLOAT\n",
      "    name: \"linear2.weight\"\n",
      "    raw_data: \"/\\330\\005@h\\263!\\300\"\n",
      "  }\n",
      "  initializer {\n",
      "    dims: 1\n",
      "    data_type: FLOAT\n",
      "    name: \"linear2.bias\"\n",
      "    raw_data: \"\\035f\\214\\276\"\n",
      "  }\n",
      "  input {\n",
      "    name: \"input.1\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 4\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 2\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"7\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: FLOAT\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 4\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  version: 9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ee3bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
